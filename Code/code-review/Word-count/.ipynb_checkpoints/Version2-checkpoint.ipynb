{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = os.chdir(\"Input/106-extracted-date\")\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# =============================================================================\n",
    "# 2. In the loop, read the speech files and split the text based on \n",
    "#     blanks (space) into words and store them in a list.\n",
    "# =============================================================================\n",
    "    \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "text_i = [open(filename, \"r\", encoding=\"latin1\").read() for filename in os.listdir(directory)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_i_token = [tokenizer.tokenize(text_i[i]) for i in range(len(text_i))]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functools import reduce\n",
    "list_all = reduce(lambda x,y: x+y,text_i_token)\n",
    "\n",
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer() \n",
    "stemmed_words = [stemmer.stem(word) for word in list_all]\n",
    "\n",
    "# Lemmatize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma_words = [lemmatizer.lemmatize(word) for word in stemmed_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Loop over words in the list and remove non‐alphanumeric characters,\n",
    "#  replace upper by lower case letters.\n",
    "# =============================================================================\n",
    " \n",
    "import re\n",
    "def remove_noAlpha(list): \n",
    "    pattern = '[0-9]'\n",
    "    list = [re.sub(pattern, '', i) for i in list] \n",
    "    return list\n",
    "list_remove_noAlpha = remove_noAlpha(lemma_words)\n",
    "str_list = list(filter(None, list_remove_noAlpha))\n",
    "list_lower=[re.sub(r'([^\\s\\w\\d]|_)+', '', item).lower() for item in str_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Use the document droplist.txt  and \n",
    "#check if the words in this list are also included in the stopword list \n",
    "#provided by the NLTK library. Join both lists in a list called stopwords_final\n",
    "# and drop these words from each list in 3.\n",
    "\n",
    "droplist_str = open(\"../droplist.txt\").read()\n",
    "droplist = droplist_str.split()\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords_nltk=nltk.corpus.stopwords.words('english')\n",
    "stopwords_final=stopwords_nltk + droplist\n",
    "remove_stopwords = [word for word in list_lower if word not in stopwords_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. Count the frequency of each remaining word and \n",
    "# save the result in a comma‐separated file in \"long\" format \n",
    "# where the first row contains the variable names: \"file\", \"word\", \"frequency\" \n",
    "# and the following rows contain the corresponding values.\n",
    "# =============================================================================\n",
    "\n",
    "from collections import Counter\n",
    "file_write=open(\"speech_counter_freq.txt\", 'w') \n",
    "#write the first line with the name of the variables\n",
    "file_write.write(\"file\" + \";\" + \"word\" + ';' + \"freq\" +  '\\n')\n",
    "\n",
    "#write each line to the .txt file\n",
    "for filename in os.listdir(dir):\n",
    "    for key, value in Counter(remove_stopwords).items(): \n",
    "        file_write.write(str(filename) + ';' + str(key) + ';' + str(value) +  '\\n')\n",
    "file_write.close()\n",
    "\n",
    "#write the dictionary to a .csv file\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Ouput/speech_counter_freq.txt', sep=\";\")\n",
    "df.to_csv('Ouput/speech_counter_freq.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
