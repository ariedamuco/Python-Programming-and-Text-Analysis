{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "\n",
    "Text data is usually represented as strings, which in turn are concatenation of characters. The type and length of text will vary accross projects.\n",
    "\n",
    "Due to it's nature, text is clearly very different from the numeric features and we will need to process it differently before we can do analysis with it and apply our machine learning algorithms to it. \n",
    "\n",
    "This notebook will cover the Naive Bayes Classifier that is one of the best ML techniques we can apply to labelled text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/ariedamuco/Dropbox (CEU Econ)/TextAnalysisCEU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('Inputs/smsspamcollection/SMSSpamCollection').readlines()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\\n',\n",
       " 'ham\\tOk lar... Joking wif u oni...\\n',\n",
       " \"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\n\",\n",
       " 'ham\\tU dun say so early hor... U c already then say...\\n',\n",
       " \"ham\\tNah I don't think he goes to usf, he lives around here though\\n\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now open the same file in pandas\n",
    "import pandas as pd\n",
    "data = pd.read_csv('Inputs/smsspamcollection/SMSSpamCollection', sep='\\t',names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    5572 non-null   object\n",
      " 1   message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4825   4516                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length'] = data['message'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1      ham                      Ok lar... Joking wif u oni...      29\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3      ham  U dun say so early hor... U c already then say...      49\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "...    ...                                                ...     ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...     160\n",
       "5568   ham               Will ü b going to esplanade fr home?      36\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...      57\n",
       "5570   ham  The guy did some bitching but I acted like i'd...     125\n",
       "5571   ham                         Rofl. Its true to its name      26\n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe9305222d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['length'].plot(bins=150, kind='hist', color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#910 characters, let's see how this looks like, use .iloc[0] to show full message\n",
    "data[data['length'] == 910]['message'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fe920812ad0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7fe93062cb90>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist(column='length', by='label',color='blue', bins=50, figsize=(10,4), range=[0, 250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-Processing\n",
    "\n",
    "The classification algorithms need numerical feature vector in order to perform the classification task. \n",
    "There are actually many methods to convert a corpus to a vector format. The simplest is the the bag-of-words approach, where each unique word in a text will be represented by one number. \n",
    "\n",
    "### Bag of Words Approach (BOW)\n",
    "\n",
    "The bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). When using this representation, we discard most of the structure of the input text and count the frequency of each word in the text. Disregarding the structure and counting only word occurrences leads to the\n",
    "mental image of representing text as a `bag`. \n",
    "\n",
    "Computing the bag-of-words representation for a corpus of documents\n",
    "consists of the following three steps: \n",
    "\n",
    "i) Tokenization: Split each document into the words `tokens`, for example by splitting them on whitespace and\n",
    "punctuation.\n",
    "\n",
    "ii) Vocabulary building:  Collect a vocabulary of all words that appear\n",
    "in any of the documents\n",
    "\n",
    "iii) Encoding: For each document, we count how many times each word appears.\n",
    "\n",
    "\n",
    "For this purpose, we will use the NLTK library (alternatively you can load the stopwords list that I have provided you with). \n",
    "NLTK library, jointly with Spacy, are standard library in Python for processing text and has a lot of useful features. We'll only use some of the basic ones here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')# Show the vector of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively \n",
    "stopwords=open('Inputs/nltk_stopwords.txt').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i\\n',\n",
       " 'me\\n',\n",
       " 'my\\n',\n",
       " 'myself\\n',\n",
       " 'we\\n',\n",
       " 'our\\n',\n",
       " 'ours\\n',\n",
       " 'ourselves\\n',\n",
       " 'you\\n',\n",
       " \"you're\\n\",\n",
       " \"you've\\n\",\n",
       " \"you'll\\n\",\n",
       " \"you'd\\n\",\n",
       " 'your\\n',\n",
       " 'yours\\n',\n",
       " 'yourself\\n',\n",
       " 'yourselves\\n',\n",
       " 'he\\n',\n",
       " 'him\\n',\n",
       " 'his\\n',\n",
       " 'himself\\n',\n",
       " 'she\\n',\n",
       " \"she's\\n\",\n",
       " 'her\\n',\n",
       " 'hers\\n',\n",
       " 'herself\\n',\n",
       " 'it\\n',\n",
       " \"it's\\n\",\n",
       " 'its\\n',\n",
       " 'itself\\n',\n",
       " 'they\\n',\n",
       " 'them\\n',\n",
       " 'their\\n',\n",
       " 'theirs\\n',\n",
       " 'themselves\\n',\n",
       " 'what\\n',\n",
       " 'which\\n',\n",
       " 'who\\n',\n",
       " 'whom\\n',\n",
       " 'this\\n',\n",
       " 'that\\n',\n",
       " \"that'll\\n\",\n",
       " 'these\\n',\n",
       " 'those\\n',\n",
       " 'am\\n',\n",
       " 'is\\n',\n",
       " 'are\\n',\n",
       " 'was\\n',\n",
       " 'were\\n',\n",
       " 'be\\n',\n",
       " 'been\\n',\n",
       " 'being\\n',\n",
       " 'have\\n',\n",
       " 'has\\n',\n",
       " 'had\\n',\n",
       " 'having\\n',\n",
       " 'do\\n',\n",
       " 'does\\n',\n",
       " 'did\\n',\n",
       " 'doing\\n',\n",
       " 'a\\n',\n",
       " 'an\\n',\n",
       " 'the\\n',\n",
       " 'and\\n',\n",
       " 'but\\n',\n",
       " 'if\\n',\n",
       " 'or\\n',\n",
       " 'because\\n',\n",
       " 'as\\n',\n",
       " 'until\\n',\n",
       " 'while\\n',\n",
       " 'of\\n',\n",
       " 'at\\n',\n",
       " 'by\\n',\n",
       " 'for\\n',\n",
       " 'with\\n',\n",
       " 'about\\n',\n",
       " 'against\\n',\n",
       " 'between\\n',\n",
       " 'into\\n',\n",
       " 'through\\n',\n",
       " 'during\\n',\n",
       " 'before\\n',\n",
       " 'after\\n',\n",
       " 'above\\n',\n",
       " 'below\\n',\n",
       " 'to\\n',\n",
       " 'from\\n',\n",
       " 'up\\n',\n",
       " 'down\\n',\n",
       " 'in\\n',\n",
       " 'out\\n',\n",
       " 'on\\n',\n",
       " 'off\\n',\n",
       " 'over\\n',\n",
       " 'under\\n',\n",
       " 'again\\n',\n",
       " 'further\\n',\n",
       " 'then\\n',\n",
       " 'once\\n',\n",
       " 'here\\n',\n",
       " 'there\\n',\n",
       " 'when\\n',\n",
       " 'where\\n',\n",
       " 'why\\n',\n",
       " 'how\\n',\n",
       " 'all\\n',\n",
       " 'any\\n',\n",
       " 'both\\n',\n",
       " 'each\\n',\n",
       " 'few\\n',\n",
       " 'more\\n',\n",
       " 'most\\n',\n",
       " 'other\\n',\n",
       " 'some\\n',\n",
       " 'such\\n',\n",
       " 'no\\n',\n",
       " 'nor\\n',\n",
       " 'not\\n',\n",
       " 'only\\n',\n",
       " 'own\\n',\n",
       " 'same\\n',\n",
       " 'so\\n',\n",
       " 'than\\n',\n",
       " 'too\\n',\n",
       " 'very\\n',\n",
       " 's\\n',\n",
       " 't\\n',\n",
       " 'can\\n',\n",
       " 'will\\n',\n",
       " 'just\\n',\n",
       " 'don\\n',\n",
       " \"don't\\n\",\n",
       " 'should\\n',\n",
       " \"should've\\n\",\n",
       " 'now\\n',\n",
       " 'd\\n',\n",
       " 'll\\n',\n",
       " 'm\\n',\n",
       " 'o\\n',\n",
       " 're\\n',\n",
       " 've\\n',\n",
       " 'y\\n',\n",
       " 'ain\\n',\n",
       " 'aren\\n',\n",
       " \"aren't\\n\",\n",
       " 'couldn\\n',\n",
       " \"couldn't\\n\",\n",
       " 'didn\\n',\n",
       " \"didn't\\n\",\n",
       " 'doesn\\n',\n",
       " \"doesn't\\n\",\n",
       " 'hadn\\n',\n",
       " \"hadn't\\n\",\n",
       " 'hasn\\n',\n",
       " \"hasn't\\n\",\n",
       " 'haven\\n',\n",
       " \"haven't\\n\",\n",
       " 'isn\\n',\n",
       " \"isn't\\n\",\n",
       " 'ma\\n',\n",
       " 'mightn\\n',\n",
       " \"mightn't\\n\",\n",
       " 'mustn\\n',\n",
       " \"mustn't\\n\",\n",
       " 'needn\\n',\n",
       " \"needn't\\n\",\n",
       " 'shan\\n',\n",
       " \"shan't\\n\",\n",
       " 'shouldn\\n',\n",
       " \"shouldn't\\n\",\n",
       " 'wasn\\n',\n",
       " \"wasn't\\n\",\n",
       " 'weren\\n',\n",
       " \"weren't\\n\",\n",
       " 'won\\n',\n",
       " \"won't\\n\",\n",
       " 'wouldn\\n',\n",
       " \"wouldn't\\n\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=[element.replace(\"\\n\", \"\") for element in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_original = \"string. With. Punctuation?\"\n",
    "string_replaced = re.sub(r'\\W',' ', string_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string  With  Punctuation '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct_tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    tokenized =text.lower()   \n",
    "    return tokenized.split()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder 1:  `\\w` means alphanumeric `[0-9a-zA-Z_]`, `\\W` = non-alphanumeric, and `\\s` stands for empty space. See http://www.pyregex.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder 2: You can also use the NLKT library to do the tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what we have done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lets', 'try', 'this', 'one']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punct_tokenize(\"let's try this one....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    clean_stopwords=\"\"\n",
    "    for element in remove_punct_tokenize(text):\n",
    "        if element not in stopwords:\n",
    "            clean_stopwords = clean_stopwords + \" \"+ element\n",
    "    return clean_stopwords.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lets try one'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"let's try this one....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go jurong point crazy available bugis n great ...\n",
       "1                                 ok lar joking wif u oni\n",
       "2       free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3                     u dun say early hor u c already say\n",
       "4             nah dont think goes usf lives around though\n",
       "                              ...                        \n",
       "5567    2nd time tried 2 contact u u 750 pound prize 2...\n",
       "5568                          ü b going esplanade fr home\n",
       "5569                          pity mood soany suggestions\n",
       "5570    guy bitching acted like id interested buying s...\n",
       "5571                                       rofl true name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['message'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer will convert text into token counts\n",
    "bow_transformer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_transformer = CountVectorizer(preprocessor = remove_stopwords).fit(data['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1),\n",
       "                preprocessor=<function remove_stopwords at 0x7fe90002e440>,\n",
       "                stop_words=None, strip_accents=None,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9423\n"
     ]
    }
   ],
   "source": [
    "print (len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "message9 = data['message'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9423)\n"
     ]
    }
   ],
   "source": [
    "bow9 = bow_transformer.transform([message9])\n",
    "print (bow9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bow9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 217)\t1\n",
      "  (0, 324)\t1\n",
      "  (0, 905)\t1\n",
      "  (0, 1941)\t1\n",
      "  (0, 2218)\t2\n",
      "  (0, 2279)\t1\n",
      "  (0, 2565)\t1\n",
      "  (0, 4235)\t1\n",
      "  (0, 4795)\t1\n",
      "  (0, 5750)\t1\n",
      "  (0, 6590)\t1\n",
      "  (0, 6827)\t1\n",
      "  (0, 6998)\t1\n",
      "  (0, 7266)\t1\n",
      "  (0, 8763)\t1\n",
      "  (0, 8767)\t1\n",
      "  (0, 9092)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what tokens are stored in (0, 217), (0, 2218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09061701461\n"
     ]
    }
   ],
   "source": [
    "print (bow_transformer.get_feature_names()[217])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim\n"
     ]
    }
   ],
   "source": [
    "print (bow_transformer.get_feature_names()[2218])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>ham</td>\n",
       "      <td>For me the love should start with attraction.i...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "1085   ham  For me the love should start with attraction.i...     910"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['length'] == 910]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_romeo = data['message'][1085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_romeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_romeo = bow_transformer.transform([message_romeo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9423)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_romeo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1161)\t1\n",
      "  (0, 1230)\t2\n",
      "  (0, 1313)\t2\n",
      "  (0, 1383)\t1\n",
      "  (0, 1556)\t2\n",
      "  (0, 1810)\t1\n",
      "  (0, 2160)\t1\n",
      "  (0, 2314)\t1\n",
      "  (0, 2495)\t1\n",
      "  (0, 2527)\t1\n",
      "  (0, 2559)\t1\n",
      "  (0, 2638)\t2\n",
      "  (0, 2914)\t1\n",
      "  (0, 2956)\t1\n",
      "  (0, 3120)\t2\n",
      "  (0, 3210)\t4\n",
      "  (0, 3369)\t1\n",
      "  (0, 3399)\t1\n",
      "  (0, 3445)\t1\n",
      "  (0, 3738)\t1\n",
      "  (0, 3761)\t1\n",
      "  (0, 3768)\t1\n",
      "  (0, 3795)\t1\n",
      "  (0, 3996)\t1\n",
      "  (0, 4005)\t1\n",
      "  :\t:\n",
      "  (0, 5363)\t1\n",
      "  (0, 5397)\t1\n",
      "  (0, 5565)\t1\n",
      "  (0, 5683)\t1\n",
      "  (0, 5684)\t1\n",
      "  (0, 5725)\t1\n",
      "  (0, 6366)\t1\n",
      "  (0, 6515)\t1\n",
      "  (0, 6639)\t1\n",
      "  (0, 6795)\t1\n",
      "  (0, 7144)\t1\n",
      "  (0, 7185)\t1\n",
      "  (0, 7474)\t1\n",
      "  (0, 7658)\t1\n",
      "  (0, 7805)\t3\n",
      "  (0, 8096)\t1\n",
      "  (0, 8174)\t1\n",
      "  (0, 8227)\t1\n",
      "  (0, 8259)\t1\n",
      "  (0, 8280)\t1\n",
      "  (0, 8282)\t1\n",
      "  (0, 8305)\t1\n",
      "  (0, 8343)\t2\n",
      "  (0, 9056)\t1\n",
      "  (0, 9193)\t3\n"
     ]
    }
   ],
   "source": [
    "print (bow_romeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (bow_transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bow_transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489 2daylove\n",
      "937 aathilove\n",
      "1572 bedroomlove\n",
      "1602 beloved\n",
      "1990 canlove\n",
      "2257 clover\n",
      "2956 dreamlove\n",
      "4099 herlove\n",
      "4186 homelove\n",
      "4295 hunlove\n",
      "4527 islove\n",
      "5123 love\n",
      "5124 loveable\n",
      "5125 loved\n",
      "5126 lovejen\n",
      "5127 lovely\n",
      "5128 loveme\n",
      "5129 lover\n",
      "5130 loverakhesh\n",
      "5131 loverboy\n",
      "5132 lovers\n",
      "5133 loves\n",
      "5624 muchxxlove\n",
      "6956 reslove\n",
      "7171 satlove\n",
      "7178 sausagelove\n",
      "7546 slovely\n",
      "9169 worklove\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(bow_transformer.get_feature_names()):\n",
    "    if \"love\" in word:\n",
    "        print (index, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform now all dataset\n",
    "data_bow = bow_transformer.transform(data['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(data_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9092)\t0.23504242276190376\n",
      "  (0, 8767)\t0.2417608717879622\n",
      "  (0, 8763)\t0.22310978582586533\n",
      "  (0, 7266)\t0.2153882708405334\n",
      "  (0, 6998)\t0.2570497663029066\n",
      "  (0, 6827)\t0.29506543469242547\n",
      "  (0, 6590)\t0.1793504751988651\n",
      "  (0, 5750)\t0.2153882708405334\n",
      "  (0, 4795)\t0.29506543469242547\n",
      "  (0, 4235)\t0.22612067118357726\n",
      "  (0, 2565)\t0.1919846371928806\n",
      "  (0, 2279)\t0.2142536330398757\n",
      "  (0, 2218)\t0.3414894763386853\n",
      "  (0, 1941)\t0.11556449460880888\n",
      "  (0, 905)\t0.2534039392300523\n",
      "  (0, 324)\t0.23714023792653083\n",
      "  (0, 217)\t0.29506543469242547\n"
     ]
    }
   ],
   "source": [
    "tfidf9 = tfidf_transformer.transform(bow9)\n",
    "print (tfidf9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.934340905340393\n"
     ]
    }
   ],
   "source": [
    "print (tfidf_transformer.idf_[bow_transformer.vocabulary_['claim']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.484025231066877\n"
     ]
    }
   ],
   "source": [
    "print (tfidf_transformer.idf_[bow_transformer.vocabulary_['love']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 9423)\n"
     ]
    }
   ],
   "source": [
    "data_tfidf = tfidf_transformer.transform(data_bow)\n",
    "print (data_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes  Classifier\n",
    "\n",
    "Naive Bayes is one of the most practical machine learning algorithms. It performs very well with text data. It learns and predicts very fast and it does not require lots of storage. It takes the name after Bayes as the Bayes theorem is applied.  It's called \"NAIVE\" because all features are assumed to be independent of each other. This is rarely the case, however, the algorithm still returns very good accuracy in practice even when the independent assumption does not hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model = MultinomialNB().fit(data_tfidf.toarray() , data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detect_model.predict(data_tfidf)\n",
    "print (all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_val = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ham\n",
      "1        ham\n",
      "2       spam\n",
      "3        ham\n",
      "4        ham\n",
      "        ... \n",
      "5567    spam\n",
      "5568     ham\n",
      "5569     ham\n",
      "5570     ham\n",
      "5571     ham\n",
      "Name: label, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (true_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check what is the prediction for tfidf9\n",
    "spam_detect_model.predict(tfidf9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      4825\n",
      "        spam       1.00      0.86      0.92       747\n",
      "\n",
      "    accuracy                           0.98      5572\n",
      "   macro avg       0.99      0.93      0.96      5572\n",
      "weighted avg       0.98      0.98      0.98      5572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(data['label'], all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(preprocessor = remove_stopwords )),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  #Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       968\n",
      "        spam       1.00      0.78      0.87       147\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now we can directly pass message text data and the pipeline will do our pre-processing for us!\n",
    "pipeline.fit(msg_train, label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "\n",
    "print (classification_report(label_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[968,   0],\n",
       "       [ 33, 114]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#tn, fp, fn, tp = confusion_matrix(label_test,predictions).ravel()\n",
    "confusion_matrix(label_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict out of sample messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"I am prince Ali, you win 2000$\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype='<U4')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"I'd like to reach you coz I miss you and I need your love\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "-Data UC Irvine https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
    "\n",
    "-Precision and recall\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "-Feature ingeneering\n",
    "https://en.wikipedia.org/wiki/Feature_engineering\n",
    "\n",
    "-Naive Bayes \n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "-Confusion matrix\n",
    "https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
